---
title: "Queries"
author: "Alun"
date: "10 December 2015"
output: pdf_document
---
Considering the problems encountered with converting to BSON and uploading. I saved preprocessing product as a csv and upload it manually with the mongo terminal. 
```{}
mongoimport "mongoData.csv" --type "CSV" --headerline --db DataScienceCoursework --collection microBlogData
use DataScienceCoursework
```

```{r Libraries, message = FALSE, echo=FALSE, cache=TRUE}
# Install / load libraries
if (!require(packrat)) {
  install.packages("packrat")
  library(packrat)
}
if (!require(dplyr)) {
  install.packages("dplyr")
  library(dplyr)
}
if (!require(rmongodb)) {
  install.packages("rmongodb")
  library(rmongodb)
}
if (!require(knitr)) {
  install.packages("knitr")
  library(knitr)
}
if (!require(stringr)){
  install.packages("stringr")
  library(stringr)
}
if (!require(ngram)){
  install.packages("ngram")
  library(ngram)
}
```
```{r setup defaults, echo=FALSE}
knitr::opts_knit$set(cache=T)
```

Initialise connection to mongoDB. 
```{r connect}
library(rmongodb)

dbse = "DataScienceCoursework"
nspse = paste(dbse, "microBlogData", sep = ".")
mongo <- mongo.create(db = dbse)
mongo.is.connected(mongo)
```

### Query 1: How many distinct users are there
For these first two queries NA values aren't included as unique users so we don't have to worry about not including them. And as shown previously the conversion from negative to positive hasn't impacted the number of unique users. 
First the mongo shell solution:
```{}
db.microBlogData.distinct( "id_member" ).length
// Result = 119232
```
And the R/rmongodb solution
```{r Query1}
res <- mongo.distinct(mongo, nspse, "id_member")
length(res)
```

### Query 2.How many tweets did the top 10% of users publish

Mongo Shell:
```{}
var top10 = db.microBlogData.aggregate(
	{
		$group: {_id : "$id_member", total : { $sum : 1}}
	},
	{
		$sort: {total : -1}
	},
	{
		$limit: 10
	},
	{
		$group: { _id : null, top10 : { $sum: "$total"}}
	}
)
// 32344
```
R/rmongoDB solution:
```{r Query 2}
# Define each pipe query and turn to BSON
pipe_1 <- mongo.bson.from.JSON('{"$group":{"_id":"$id_member","total":{"$sum":1}}}')
pipe_2 <- mongo.bson.from.JSON('{"$sort":{"total":-1}}')
pipe_3 <- mongo.bson.from.JSON('{"$limit":10}')
pipe_4 <- mongo.bson.from.JSON('{"$group" : { "_id" : null, "top10" : { "$sum": "$total"}}}')
# Stitch Queries together
cmd_list <- list(pipe_1, pipe_2, pipe_3, pipe_4)
# Evaluate quereis
res <- mongo.aggregation(mongo, nspse, cmd_list)
# Transform result into R object
top10 <- mongo.bson.to.Robject(res)
top10
# Count total number of tweets
total <- mongo.count(mongo, nspse)

# calculate percentage
(top10$result$`0`$top10 / total)*100
```
### Query3:  What was the earliest and latest date (YYYY-MM-DD HH:MM:SS) that a message was published?

```{r Query 3}
#First
first <- mongo.find.all(mongo, nspse, fields = '{"timestamp":1}', 
                       sort = '{"timestamp":1}',
                       limit = 1L)[[1]]$timestamp
#Last
last <- mongo.find.all(mongo, nspse, fields = '{"timestamp":1}',
                       query = '{"timestamp" : { "$ne" : "NA" }}',
                       sort = '{"timestamp":-1}',
                       limit = 1L)[[1]]$timestamp
first
last
```

### Query 4: What is the mean delta time between the messages. 
Mean delta time is the total time between messages in seconds divided by the number of messages - 1. 
Convert first and last time data to posixct and then do an integer typed subtraction. 
```{r Query 4}
timeTotal <- as.integer(as.POSIXct(last, tz="UTC")) - as.integer(as.POSIXct(first, tz = "UTC"))
deltaMean <- timeTotal / (mongo.count(mongo, nspse) - 1 )
deltaMean
```
Queries 5-8 all apply to string manipulation so we use a cursor to save the text as an R object. 
```{r Retrieving Text}
#text <- mongo.find.all(mongo, nspse, fields = '{"text":1}',data.frame = T)
```
## Query 5 get the mean length of a message
Create a cursor and calculate the sum of characters in each text field into a sum before dividing by non-na counts. 
```{r Query 5}
sum = 0
cursor <- mongo.find(mongo, nspse, fields = '{"text":1}', 
                     query = '{"text" : {"$ne" : "NA"}}')
while (mongo.cursor.next(cursor)) {
val <- mongo.cursor.value(cursor)
sum <- sum + nchar(mongo.bson.value(val, "text"))
}

count <- mongo.count(mongo, nspse, query = '{"text" : {"$ne" : "NA"}}')
sum / count
```

## Most common unigram and bigrams
The method here is to load the text into a cursor, split each ngram with the 'ngram' r package and save it in another collection. Finally use the group query to collect like unigrams together and sum them. 
Getting a very difficult error when I try to use bigrams instead of unigrams. In theory you jus tchang ethe value inside the get.ngrams function to 2. But mongodb doesn't recogise some of the objects as bson. 
```{r Query 6}
# cursor <- mongo.find(mongo, nspse, fields = '{"text":1}', 
#                      query = '{"text" : {"$ne" : "NA"}}')
# while (mongo.cursor.next(cursor)) {
#   val <- mongo.bson.value(mongo.cursor.value(cursor), "text")
#   ngram <- get.ngrams(ngram(val, 1))
#   sapply(ngram, function(x) {
#     mongo.insert(mongo, "DataScienceCoursework.unigrams",  
#                  mongo.bson.from.list(as.list(x)))
#   })
# }
```
While I intended to save these to a mongodb colleciton, continuing buggs uploading a few of the data points meant I saved it as an R vector instead. 
```{r saving unigrams to R}
# unigram = vector()
# i = 1
# cursor <- mongo.find(mongo, nspse, fields = '{"text":1}', 
#                      query = '{"text" : {"$ne" : "NA"}}')
# while (mongo.cursor.next(cursor)) {
#   val <- mongo.bson.value(mongo.cursor.value(cursor), "text")
#   ngram <- get.ngrams(ngram(as.character(val), 1))
#   sapply(ngram, function(x) {
#     unigram[i] <- x
#   }
# )
#   i <- i + 1
#   }
```

```{r saving bigrams to R}
# bigram = vector()
# i = 1
# cursor <- mongo.find(mongo, nspse, fields = '{"text":1}', 
#                      query = '{"text" : {"$ne" : "NA"}}')
# while (mongo.cursor.next(cursor)) {
#   val <- mongo.bson.value(mongo.cursor.value(cursor), "text")
#   ngram <- get.ngrams(ngram(val, 1))
#   sapply(ngram, function(x) {
#     bigram[i] <- x
#     }
#     )
#   i <- i + 1
#   print(i)
#   }

```

##What is the average number of hashtags (#) used within a message? 
Similar query 5 but with counting hashtags instead of strings. 
```{r Query 7}
sum = 0
cursor <- mongo.find(mongo, nspse, fields = '{"text":1}', 
                     query = '{"text" : {"$ne" : "NA"}}')
while (mongo.cursor.next(cursor)) {
  val <- mongo.bson.value(mongo.cursor.value(cursor), "text")
  sum <- sum + str_count(val, "#")
}
sum / count
```
## Query 8, which area of the UK has the most tweets. 
Split the uk into a grid between -7.7:8.9 and 49:60

```{r Query 8}
laSeq <- seq(-7.7,8.9,0.1)
loSeq <- seq(49,60,0.1)
index <- NULL
# Create a cursor of all longetude and latitude objects
cursor <- mongo.find(mongo, nspse, fields = '{"geo_lng" : 1 , "geo_lat" : 1}')
"cursor complete"
while (mongo.cursor.next(cursor)) {
  for (i in seq_along(laSeq))
  {
    for (j in seq_along(loSeq)) 
      {
          lng <- mongo.bson.value(mongo.cursor.value(cursor), "geo_lng")
          lat <- mongo.bson.value(mongo.cursor.value(cursor), "geo_lat")
          if (is.na(lat) &  is.na(lng))
          {
              if ((lat >= laSeq[i]) & (lat < laSeq[i+1]) & ( lng >= loSeq[i] ) & (lng < loSeq[i+1])){
                print("saved")
                index$lat[i] <- laSeq[i]
                index$loSeq[j] <- loSeq[j]
              }
          }
      }
  }
}
mongo.cursor.destroy(cursor)
```

```{r}
mongo2 <- mongo.create(db = "DatScienceCoursework")
name <- "DatScienceCoursework.mtcars"
cursor <- mongo.find.all(mongo, nspse, fields = '{"geo_lng" : 1 , "geo_lat" : 1}')

```